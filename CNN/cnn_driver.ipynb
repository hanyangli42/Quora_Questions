{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "from IPython.display import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "\n",
    "from torch.nn.utils import rnn\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from utils import Dataset, get_script_short_name\n",
    "import time\n",
    "\n",
    "from cnn_main import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load npz data sets\n",
    "train_set = np.load('train.npz')\n",
    "dev_set = np.load('dev.npz')\n",
    "test_set = np.load('test.npz')\n",
    "\n",
    "train_q1 = train_set['arr_0']\n",
    "train_q2 = train_set['arr_1']\n",
    "train_y = train_set['arr_2']\n",
    "dev_q1 = dev_set['arr_0']\n",
    "dev_q2 = dev_set['arr_1']\n",
    "dev_y = dev_set['arr_2']\n",
    "test_q1 = test_set['arr_0']\n",
    "test_q2 = test_set['arr_1']\n",
    "test_y = test_set['arr_2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 271 # max sequence length in the dataset\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets using the customized dataset and customized dataloader\n",
    "train_dataset = DQIDataset(train_q1, train_q2, train_y, max_len)\n",
    "dev_dataset = DQIDataset(dev_q1, dev_q2, dev_y, max_len)\n",
    "test_dataset = DQIDataset(test_q1, test_q2, test_y, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, drop_last = True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size = batch_size, shuffle = False, drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, drop_last = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQINetwork(\n",
       "  (embedding_network): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(5,), stride=(2,), bias=False)\n",
       "    (1): ELU(alpha=1.0, inplace)\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (elu): ELU(alpha=1.0, inplace)\n",
       "      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Conv1d(32, 64, kernel_size=(5,), stride=(2,), bias=False)\n",
       "    (4): ELU(alpha=1.0, inplace)\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (elu): ELU(alpha=1.0, inplace)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): Conv1d(64, 128, kernel_size=(5,), stride=(2,), bias=False)\n",
       "    (7): ELU(alpha=1.0, inplace)\n",
       "    (8): BasicBlock(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (elu): ELU(alpha=1.0, inplace)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): Conv1d(128, 300, kernel_size=(5,), stride=(2,), bias=False)\n",
       "    (10): ELU(alpha=1.0, inplace)\n",
       "    (11): BasicBlock(\n",
       "      (conv1): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (elu): ELU(alpha=1.0, inplace)\n",
       "      (conv2): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): Flatten()\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): Linear(in_features=600, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = DQINetwork()\n",
    "if torch.cuda.is_available():\n",
    "    network.cuda()\n",
    "network.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(),lr=0.001)\n",
    "epoch_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1] epoch_loss: 2.091, batch_loss: 2.091\n",
      "Training Acc: 38%\n",
      "[1, 51] epoch_loss: 35.357, batch_loss: 0.680\n",
      "Training Acc: 63%\n",
      "[1, 101] epoch_loss: 66.434, batch_loss: 0.593\n",
      "Training Acc: 64%\n",
      "[1, 151] epoch_loss: 97.274, batch_loss: 0.641\n",
      "Training Acc: 64%\n",
      "[1, 201] epoch_loss: 127.731, batch_loss: 0.616\n",
      "Training Acc: 65%\n",
      "[1, 251] epoch_loss: 157.881, batch_loss: 0.543\n",
      "Training Acc: 65%\n",
      "[1, 301] epoch_loss: 188.253, batch_loss: 0.617\n",
      "Training Acc: 65%\n",
      "[1, 351] epoch_loss: 218.631, batch_loss: 0.615\n",
      "Training Acc: 66%\n",
      "[1, 401] epoch_loss: 248.405, batch_loss: 0.616\n",
      "Training Acc: 66%\n",
      "[1, 451] epoch_loss: 278.550, batch_loss: 0.600\n",
      "Training Acc: 66%\n",
      "[1, 501] epoch_loss: 308.292, batch_loss: 0.685\n",
      "Training Acc: 66%\n",
      "[1, 551] epoch_loss: 338.344, batch_loss: 0.486\n",
      "Training Acc: 66%\n",
      "[1, 601] epoch_loss: 368.126, batch_loss: 0.649\n",
      "Training Acc: 66%\n",
      "[1, 651] epoch_loss: 397.588, batch_loss: 0.588\n",
      "Training Acc: 66%\n",
      "[1, 701] epoch_loss: 426.649, batch_loss: 0.536\n",
      "Training Acc: 66%\n",
      "[1, 751] epoch_loss: 456.311, batch_loss: 0.582\n",
      "Training Acc: 66%\n",
      "[1, 801] epoch_loss: 485.672, batch_loss: 0.604\n",
      "Training Acc: 66%\n",
      "[1, 851] epoch_loss: 515.254, batch_loss: 0.621\n",
      "Training Acc: 67%\n",
      "[1, 901] epoch_loss: 544.781, batch_loss: 0.601\n",
      "Training Acc: 67%\n",
      "[1, 951] epoch_loss: 574.354, batch_loss: 0.596\n",
      "Training Acc: 67%\n",
      "[1, 1001] epoch_loss: 603.783, batch_loss: 0.588\n",
      "Training Acc: 67%\n",
      "[1, 1051] epoch_loss: 633.364, batch_loss: 0.571\n",
      "Training Acc: 67%\n",
      "[1, 1101] epoch_loss: 662.807, batch_loss: 0.611\n",
      "Training Acc: 67%\n",
      "[1, 1151] epoch_loss: 692.626, batch_loss: 0.579\n",
      "Training Acc: 67%\n",
      "[1, 1201] epoch_loss: 722.373, batch_loss: 0.553\n",
      "Training Acc: 67%\n",
      "[1, 1251] epoch_loss: 751.593, batch_loss: 0.688\n",
      "Training Acc: 67%\n",
      "[1, 1301] epoch_loss: 781.342, batch_loss: 0.653\n",
      "Training Acc: 67%\n",
      "[1, 1351] epoch_loss: 811.000, batch_loss: 0.594\n",
      "Training Acc: 67%\n",
      "[1, 1401] epoch_loss: 840.681, batch_loss: 0.586\n",
      "Training Acc: 67%\n",
      "[1, 1451] epoch_loss: 869.829, batch_loss: 0.539\n",
      "Training Acc: 67%\n",
      "[1, 1501] epoch_loss: 899.378, batch_loss: 0.577\n",
      "Training Acc: 67%\n",
      "[1, 1551] epoch_loss: 929.103, batch_loss: 0.628\n",
      "Training Acc: 67%\n",
      "[1, 1601] epoch_loss: 958.660, batch_loss: 0.641\n",
      "Training Acc: 67%\n",
      "[1, 1651] epoch_loss: 987.586, batch_loss: 0.650\n",
      "Training Acc: 67%\n",
      "[1, 1701] epoch_loss: 1016.640, batch_loss: 0.583\n",
      "Training Acc: 67%\n",
      "[1, 1751] epoch_loss: 1045.821, batch_loss: 0.614\n",
      "Training Acc: 67%\n",
      "[1, 1801] epoch_loss: 1075.289, batch_loss: 0.640\n",
      "Training Acc: 67%\n",
      "[1, 1851] epoch_loss: 1104.817, batch_loss: 0.559\n",
      "Training Acc: 67%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b054434a9247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Quora_Questions/CNN/cnn_main.py\u001b[0m in \u001b[0;36mtrain_val\u001b[0;34m(network, train_loader, dev_loader, criterion, optimizer, epoch_num, device)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# loss of the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# cumulative loss of current epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mtotal_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_val(network, train_loader, dev_loader, criterion, optimizer, epoch_num, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
