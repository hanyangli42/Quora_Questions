{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo rm -f /etc/boto.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "import Levenshtein as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from fuzzywuzzy import fuzz\n",
    "from scipy.spatial.distance import cosine, jaccard, euclidean\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(\"questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404351\n"
     ]
    }
   ],
   "source": [
    "print(len(original_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.dropna(axis=0, how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404348\n"
     ]
    }
   ],
   "source": [
    "print(len(original_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label = original_data.is_duplicate.tolist()\n",
    "all_data = original_data[['question1', 'question2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_label, test_label = train_test_split(all_data, all_label, \n",
    "                                                                  test_size=0.15, stratify=all_label,\n",
    "                                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_data.npy\", train_data)\n",
    "np.save(\"test_data.npy\", test_data)\n",
    "np.save(\"train_label.npy\", train_label)\n",
    "np.save(\"test_label.npy\", test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vec(s):\n",
    "    words = s.lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(model[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(data):\n",
    "    feats = []\n",
    "    for i, (q1, q2) in enumerate(tqdm(data)):\n",
    "        #try:\n",
    "        q1_token = word_tokenize(q1)\n",
    "        q2_token = word_tokenize(q2)\n",
    "        q1_pos_tag = [k for t, k in pos_tag(q1_token)]\n",
    "        q2_pos_tag = [k for t, k in pos_tag(q2_token)]\n",
    "        #print(q1pos_tag)\n",
    "        #print(q2pos_tag)\n",
    "            \n",
    "        q1_embedding = []\n",
    "        for t in q1_token:\n",
    "            try:\n",
    "                q1_embedding.append(model[t])\n",
    "            except:\n",
    "                continue\n",
    "        q2_embedding = []\n",
    "        for t in q2_token:\n",
    "            try:\n",
    "                q2_embedding.append(model[t])\n",
    "            except:\n",
    "                continue\n",
    "                    \n",
    "        q1_embedding = np.mean(np.array(np.nan_to_num(q1_embedding)), axis=0)\n",
    "        q2_embedding = np.mean(np.array(np.nan_to_num(q2_embedding)), axis=0)\n",
    "            \n",
    "        len_q1 = len(q1_token)\n",
    "        len_q2 = len(q2_token)\n",
    "        num_common_tags = len(set(q1_pos_tag).intersection(set(q2_pos_tag)))\n",
    "        num_common_words = len(set(q1.lower().split(' ')).intersection(set(q2.lower().split(' '))))\n",
    "            \n",
    "        L_words_dist = L.distance(q1, q2)\n",
    "        L_tag_dist = L.distance(\" \".join(q1_pos_tag), \" \".join(q2_pos_tag))\n",
    "            \n",
    "        embedding_cos_sim = cosine(np.nan_to_num(q1_embedding), np.nan_to_num(q2_embedding))\n",
    "        embedding_euclidean = euclidean(np.nan_to_num(q1_embedding), np.nan_to_num(q2_embedding))\n",
    "        embedding_jaccard = jaccard(np.nan_to_num(q1_embedding), np.nan_to_num(q2_embedding))\n",
    "                \n",
    "        q_ratio = fuzz.QRatio(q1, q2)\n",
    "        wr_ratio = fuzz.WRatio(q1, q2)\n",
    "        partial_ratio = fuzz.partial_ratio(q1, q2)\n",
    "            \n",
    "        q1_kur = kurtosis(np.nan_to_num(q1_embedding))\n",
    "        q2_kur = kurtosis(np.nan_to_num(q2_embedding))\n",
    "        q1_skew = skew(np.nan_to_num(q1_embedding))\n",
    "        q2_skew = skew(np.nan_to_num(q2_embedding))\n",
    "        \n",
    "        feats.append([len_q1, len_q2, num_common_tags, num_common_words, \n",
    "                      embedding_cos_sim, embedding_euclidean, embedding_jaccard,\n",
    "                      L_words_dist, L_tag_dist,\n",
    "                      q_ratio, wr_ratio, partial_ratio,\n",
    "                      q1_kur, q2_kur, q1_skew, q2_skew]) \n",
    "        #except:\n",
    "        #    print(q1)\n",
    "        #    print(q2)\n",
    "\n",
    "    return np.array(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4273/343695 [00:17<23:24, 241.60it/s]/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "100%|██████████| 343695/343695 [21:09<00:00, 270.75it/s]\n",
      "100%|██████████| 60653/60653 [03:43<00:00, 271.87it/s]\n"
     ]
    }
   ],
   "source": [
    "train_feats = feature_extract(train_data)\n",
    "test_feats = feature_extract(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343695\n",
      "343695\n"
     ]
    }
   ],
   "source": [
    "print(len(train_feats))\n",
    "print(len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60653\n",
      "60653\n"
     ]
    }
   ],
   "source": [
    "print(len(test_feats))\n",
    "print(len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest = RandomForestClassifier(max_depth=5, n_estimators=100, max_features=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.00000000e+00  4.00000000e+00  4.00000000e+00 ... -1.01289021e-01\n",
      "   1.10726163e-01  1.92913078e-02]\n",
      " [ 1.10000000e+01  1.00000000e+01  1.00000000e+01 ...  3.37087552e-01\n",
      "   1.56232789e-01  1.12447046e-01]\n",
      " [ 8.00000000e+00  8.00000000e+00  8.00000000e+00 ... -3.26335128e-01\n",
      "   2.03394350e-02  4.99404781e-02]\n",
      " ...\n",
      " [ 9.00000000e+00  1.00000000e+01  6.00000000e+00 ... -6.10099738e-03\n",
      "   8.74593947e-03  4.18575145e-02]\n",
      " [ 1.30000000e+01  1.10000000e+01  7.00000000e+00 ... -8.63220200e-02\n",
      "   5.09598106e-02  6.46400265e-03]\n",
      " [ 1.10000000e+01  1.10000000e+01  7.00000000e+00 ... -2.71655870e-01\n",
      "  -1.56343251e-01 -1.25389889e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features=7, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest.fit(np.nan_to_num(train_feats), train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest.score(np.nan_to_num(test_feats), test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
